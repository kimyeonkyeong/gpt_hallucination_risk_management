{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ§  GPT í™˜ê° í‰ê°€ íŒŒì´í”„ë¼ì¸ (í˜•ë²• ì¡°ë¬¸ + íŒë¡€ ìš”ì•½)\n",
        "- ì§ˆë¬¸ + GPT ì‘ë‹µ\n",
        "- í˜•ë²• ì¡°ë¬¸ ê¸°ë°˜ ìœ ì‚¬ë„ + NLI í‰ê°€\n",
        "- íŒë¡€ ìš”ì•½ ê¸°ë°˜ ìœ ì‚¬ë„ + NLI í‰ê°€"
      ],
      "metadata": {
        "id": "bTxtcioBUVpS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IGpAaL2uZzwK"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers sentence-transformers pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/kimyeonkyeong/gpt_hallucination_risk_management.git\n",
        "%cd gpt_hallucination_risk_management\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfhAIx3Td46H",
        "outputId": "5b6cfb67-624f-483c-82a3-306a8dc19540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'gpt_hallucination_risk_management' already exists and is not an empty directory.\n",
            "/content/gpt_hallucination_risk_management\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… ê¸°ë³¸ ëª¨ë“ˆ ë¡œë“œ\n",
        "import pandas as pd\n",
        "import json\n",
        "from check_similarity import find_most_similar_laws, find_most_similar_cases\n",
        "from check_entailment import check_entailment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKhr35IJn_q4",
        "outputId": "c57ef9ee-940c-4055-d7f6-1f58db9947b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… ë°ì´í„° ë¡œë“œ\n",
        "df = pd.read_csv(\"law_articles.csv\")\n",
        "with open(\"example_qa.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    qa_data = json.load(f)\n",
        "with open(\"case_laws.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    case_data = json.load(f)\n",
        "case_df = pd.DataFrame(case_data)"
      ],
      "metadata": {
        "id": "JPFQFw1MoBy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… í‰ê°€ ì‹¤í–‰ (ì²˜ìŒ 1ê°œ ì˜ˆì‹œ)\n",
        "for idx, item in enumerate(qa_data[:1]):\n",
        "    question = item[\"question\"]\n",
        "    gpt_answer = item[\"gpt_answer\"]\n",
        "\n",
        "    print(\"=\"*100)\n",
        "    print(f\"ğŸ“Œ ì§ˆë¬¸ {idx+1}: {question}\")\n",
        "    print(f\"ğŸ“Œ GPT ì‘ë‹µ: {gpt_answer}\\n\")\n",
        "\n",
        "    # ğŸ” í˜•ë²• ì¡°ë¬¸ í‰ê°€\n",
        "    filtered = df  # ì „ì²´ ì¡°ë¬¸ ì‚¬ìš© (í•„í„°ë§ì€ ì„ íƒì‚¬í•­)\n",
        "    top_laws = find_most_similar_laws(question, gpt_answer, filtered)\n",
        "    print(\"ğŸ“š í˜•ë²• ì¡°ë¬¸ ê¸°ë°˜ í‰ê°€\")\n",
        "    for i, law in enumerate(top_laws):\n",
        "        print(f\"â–¶ ìœ ì‚¬ ì¡°ë¬¸ {i+1}: {law['ì¡°ë¬¸ë‚´ìš©']}\")\n",
        "        label, probs = check_entailment(law['ì¡°ë¬¸ë‚´ìš©'], gpt_answer)\n",
        "        print(f\"   â®• NLI ê²°ê³¼: {label} / ì‹ ë¢°ë„: {probs}\\n\")\n",
        "\n",
        "    # ğŸ” íŒë¡€ ìš”ì•½ í‰ê°€\n",
        "    top_cases = find_most_similar_cases(question, gpt_answer, case_df)\n",
        "    print(\"ğŸ“š íŒë¡€ ìš”ì•½ ê¸°ë°˜ í‰ê°€\")\n",
        "    for i, case in enumerate(top_cases):\n",
        "        print(f\"â–¶ ìœ ì‚¬ íŒë¡€ {i+1}: {case['summary']}\")\n",
        "        label, probs = check_entailment(case['summary'], gpt_answer)\n",
        "        print(f\"   â®• NLI ê²°ê³¼: {label} / ì‹ ë¢°ë„: {probs}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P29x4zRyoB3A",
        "outputId": "b64c0a11-0ae7-4d88-f454-79a208ff1f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ğŸ“Œ ì§ˆë¬¸ 1: ì‚´ì¸ì£„ì˜ í˜•ë²Œì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?\n",
            "ğŸ“Œ GPT ì‘ë‹µ: ì‚´ì¸ì£„ëŠ” ì‚¬í˜•, ë¬´ê¸° ë˜ëŠ” 5ë…„ ì´ìƒì˜ ì§•ì—­ì— ì²˜í•©ë‹ˆë‹¤.\n",
            "â–¶ ìœ ì‚¬ ì¡°ë¬¸ 1: â‘  ì‚¬ëŒì˜ ì´‰íƒì´ë‚˜ ìŠ¹ë‚™ì„ ë°›ì•„ ê·¸ë¥¼ ì‚´í•´í•œ ìëŠ” 1ë…„ ì´ìƒ 10ë…„ ì´í•˜ì˜ ì§•ì—­ì— ì²˜í•œë‹¤. â‘¡ ì‚¬ëŒì„ êµì‚¬í•˜ê±°ë‚˜ ë°©ì¡°í•˜ì—¬ ìì‚´í•˜ê²Œ í•œ ìë„ ì œ1í•­ì˜ í˜•ì— ì²˜í•œë‹¤. [ì „ë¬¸ê°œì • 2020. 12. 8.]\n",
            "   â®• NLI ê²°ê³¼: neutral / ì‹ ë¢°ë„: [0.3776, 0.6224]\n",
            "â–¶ ìœ ì‚¬ ì¡°ë¬¸ 2: â‘  ê²½í•©ë²”ì„ ë™ì‹œì— íŒê²°í•  ë•Œì—ëŠ” ë‹¤ìŒ ê° í˜¸ì˜ êµ¬ë¶„ì— ë”°ë¼ ì²˜ë²Œí•œë‹¤. 1. ê°€ì¥ ë¬´ê±°ìš´ ì£„ì— ëŒ€í•˜ì—¬ ì •í•œ í˜•ì´ ì‚¬í˜•, ë¬´ê¸°ì§•ì—­, ë¬´ê¸°ê¸ˆê³ ì¸ ê²½ìš°ì—ëŠ” ê°€ì¥ ë¬´ê±°ìš´ ì£„ì— ëŒ€í•˜ì—¬ ì •í•œ í˜•ìœ¼ë¡œ ì²˜ë²Œí•œë‹¤. 2. ê° ì£„ì— ëŒ€í•˜ì—¬ ì •í•œ í˜•ì´ ì‚¬í˜•, ë¬´ê¸°ì§•ì—­, ë¬´ê¸°ê¸ˆê³  ì™¸ì˜ ê°™ì€ ì¢…ë¥˜ì˜ í˜•ì¸ ê²½ìš°ì—ëŠ” ê°€ì¥ ë¬´ê±°ìš´ ì£„ì— ëŒ€í•˜ì—¬ ì •í•œ í˜•ì˜ ì¥ê¸° ë˜ëŠ” ë‹¤ì•¡(å¤šé¡)ì— ê·¸ 2ë¶„ì˜ 1ê¹Œì§€ ê°€ì¤‘í•˜ë˜ ê° ì£„ì— ëŒ€í•˜ì—¬ ì •í•œ í˜•ì˜ ì¥ê¸° ë˜ëŠ” ë‹¤ì•¡ì„ í•©ì‚°í•œ í˜•ê¸° ë˜ëŠ” ì•¡ìˆ˜ë¥¼ ì´ˆê³¼í•  ìˆ˜ ì—†ë‹¤. ë‹¤ë§Œ, ê³¼ë£Œì™€ ê³¼ë£Œ, ëª°ìˆ˜ì™€ ëª°ìˆ˜ëŠ” ë³‘ê³¼(å€‚ç§‘)í•  ìˆ˜ ìˆë‹¤. 3. ê° ì£„ì— ëŒ€í•˜ì—¬ ì •í•œ í˜•ì´ ë¬´ê¸°ì§•ì—­, ë¬´ê¸°ê¸ˆê³  ì™¸ì˜ ë‹¤ë¥¸ ì¢…ë¥˜ì˜ í˜•ì¸ ê²½ìš°ì—ëŠ” ë³‘ê³¼í•œë‹¤. â‘¡ ì œ1í•­ ê° í˜¸ì˜ ê²½ìš°ì— ì§•ì—­ê³¼ ê¸ˆê³ ëŠ” ê°™ì€ ì¢…ë¥˜ì˜ í˜•ìœ¼ë¡œ ë³´ì•„ ì§•ì—­í˜•ìœ¼ë¡œ ì²˜ë²Œí•œë‹¤. [ì „ë¬¸ê°œì • 2020. 12. 8.]\n",
            "   â®• NLI ê²°ê³¼: neutral / ì‹ ë¢°ë„: [0.3614, 0.6386]\n",
            "â–¶ ìœ ì‚¬ ì¡°ë¬¸ 3: ê°•ë„ê°€ ì‚¬ëŒì„ ì‚´í•´í•œ ë•Œì—ëŠ” ì‚¬í˜• ë˜ëŠ” ë¬´ê¸°ì§•ì—­ì— ì²˜í•œë‹¤. ì‚¬ë§ì— ì´ë¥´ê²Œ í•œ ë•Œì—ëŠ” ë¬´ê¸° ë˜ëŠ” 10ë…„ ì´ìƒì˜ ì§•ì—­ì— ì²˜í•œë‹¤. [ì „ë¬¸ê°œì • 1995. 12. 29.]\n",
            "   â®• NLI ê²°ê³¼: neutral / ì‹ ë¢°ë„: [0.376, 0.624]\n",
            "====================================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L1cEnZWPoB6-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}